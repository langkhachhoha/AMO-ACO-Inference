{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from Model.AMO import * \n",
    "\n",
    "'''\n",
    "Hướng dẫn:\n",
    "- Chính với Cường chạy theo từng phần của mình, trước khi chạy thì làm trống file Solution.txt như bấy lâu nay\n",
    "- Chính chạy 2 task, xong task 1 thì sang task 2 luôn. 2 cái này chạy nhanh \n",
    "- Cường chạy xong thì điền kết quả vào cột ACO trong excel \n",
    "Note: File có dạng data_gen/... là của bộ data tự sinh. Chính là chạy data tự sinh, gồm 10 bộ thôi. Task 1 là của AMO-ACO, Task 2 là của ACO. \n",
    "Chạy xong thì điền kq vào file excel mới. \n",
    "\n",
    "Cố gắng chạy xong luôn trong hôm nay đi, này nhanh. Còn nhiều cái phải chạy nữa \n",
    "'''\n",
    "\n",
    "# # --------------------------Chinh--------------------------\n",
    "# # Task 1 \n",
    "# file = ['data_gen/gen0.txt', 'data_gen/gen1.txt','data_gen/gen2.txt','data_gen/gen3.txt',\n",
    "#         'data_gen/gen4.txt','data_gen/gen5.txt','data_gen/gen6.txt','data_gen/gen7.txt',\n",
    "#         'data_gen/gen8.txt','data_gen/gen9.txt']\n",
    "# idx = 1\n",
    "# options = 0\n",
    "# with open('Data.txt', 'w') as outfile:\n",
    "#     file_path = file[idx]\n",
    "#     with open(file_path) as infile:\n",
    "#         for line in infile:\n",
    "#             outfile.write(line)\n",
    "# model = Net3().to(device)\n",
    "# model.load_state_dict(torch.load('AMO-ACO-100.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "# # Task 2\n",
    "# file = ['data_gen/gen0.txt', 'data_gen/gen1.txt','data_gen/gen2.txt','data_gen/gen3.txt',\n",
    "#         'data_gen/gen4.txt','data_gen/gen5.txt','data_gen/gen6.txt','data_gen/gen7.txt',\n",
    "#         'data_gen/gen8.txt','data_gen/gen9.txt']\n",
    "# idx = 0\n",
    "# options = 2 \n",
    "# with open('Data.txt', 'w') as outfile:\n",
    "#     file_path = file[idx]\n",
    "#     with open(file_path) as infile:\n",
    "#         for line in infile:\n",
    "#             outfile.write(line)\n",
    "# model = Net3().to(device)\n",
    "# model.load_state_dict(torch.load('AMO-ACO-100.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------Cuong--------------------------\n",
    "file = [\n",
    "     'C206.txt',\n",
    " 'C207.txt',\n",
    " 'C104.txt',\n",
    " 'C105.txt',\n",
    " 'C107.txt',\n",
    "  'C208.txt',\n",
    "\n",
    " 'R112.txt',\n",
    " 'R107.txt',\n",
    " 'R110.txt',\n",
    " 'R207.txt',\n",
    " 'R210.txt',\n",
    " 'R209.txt',\n",
    "\n",
    " 'RC107.txt',\n",
    "'RC108.txt',\n",
    "'RC109.txt',\n",
    "'RC206.txt',\n",
    "'RC207.txt',\n",
    "'RC208.txt'\n",
    "]\n",
    "\n",
    "\n",
    " \n",
    "# Doi reward_coef phu họp \n",
    "r_coef = -1 # Cuong \n",
    "r_coef = 0 # Cuong \n",
    "r_coef = 2 # Chinh \n",
    "r_coef = 4 # Chinh \n",
    "# --------------------------------------------\n",
    "idx = 0\n",
    "options = 0 \n",
    "with open('Data.txt', 'w') as outfile:\n",
    "    file_path = 'txt/' + file[idx]\n",
    "    with open(file_path) as infile:\n",
    "        for line in infile:\n",
    "            outfile.write(line)\n",
    "model = Net3().to(device)\n",
    "model.load_state_dict(torch.load('AMO-ACO-100.pt', map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Categorical\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from copy import deepcopy\n",
    "import math \n",
    "import numpy as np\n",
    "from Model.Config import *\n",
    "from Model.AMO import * \n",
    "from Ant_k_starts import *\n",
    "from Normalize_data import *\n",
    "from Ant import *\n",
    "from Injection import *\n",
    "from Cross_Exchange import *\n",
    "from Local_search import * \n",
    "from Draw import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = None\n",
    "cfg = Data_100()\n",
    "EPS = 1e-10\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyg_data_normalize = normalize_data(cfg)\n",
    "heuristic_measure, log, topk = model(pyg_data_normalize)\n",
    "heuristic_measure = heuristic_measure.reshape((cfg.graph_size+1, cfg.graph_size+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cap, xcoord, ycoord, demand, e_time, l_time, s_time, data = load_data()\n",
    "\n",
    "data = torch.tensor([[float(x) for x in y] for y in data])\n",
    "tsp_coordinates = data[:, 1:3] \n",
    "demands = torch.tensor(demand, dtype = torch.float32)\n",
    "time_window = data[:, 4:]\n",
    "durations = time_window[:, -1] \n",
    "distances = gen_distance_matrix(tsp_coordinates, device = device)\n",
    "if options == 0:\n",
    "    aco = ACO(distances, demands, time_window, 10, topk, max_cap, options=options, heuristic=heuristic_measure, n_ants=cfg.n_ants)\n",
    "else:\n",
    "    aco = ACO(distances, demands, time_window, 10, topk, max_cap, options=options, n_ants=cfg.n_ants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cap, xcoord, ycoord, demand, e_time, l_time, s_time, data = load_data()\n",
    "\n",
    "CAP=max_cap\n",
    "colony=Ant(data,CAP,0.7, heuristic_measure)\n",
    "colony.customer_cord()\n",
    "colony.euclidean_distance()\n",
    "colony.width_window()\n",
    "_ = colony.path_pheromon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict(path): # path: tensor depot 0(m,)\n",
    "    path += 1\n",
    "    path = path.to(torch.long)\n",
    "    zero_indices = torch.where(path == 1)[0]\n",
    "    zero_indices = zero_indices.tolist()\n",
    "    path = path.tolist()\n",
    "    while zero_indices[-1] - zero_indices[-2] == 1:\n",
    "        zero_indices.pop()\n",
    "    dict = {}\n",
    "    for i in range(len(zero_indices) - 1):\n",
    "        dict[i] = path[zero_indices[i]: zero_indices[i+1] + 1 ]\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_btnt(path, cost, pheromone, effort, k_candidate, prob_to_update, reward_coff, best_cost, d = 2):\n",
    "    '''\n",
    "    path: Loi giai tiem nang\n",
    "    cost: ham cost cua loi giai\n",
    "    pheromone: aco.pheromone\n",
    "    effort: so iter truoc khi ket thuc\n",
    "    ''' \n",
    "    if cost < best_cost:\n",
    "        reward = int(k_candidate * prob_to_update * reward_coff) * effort\n",
    "    else:\n",
    "        reward = int(k_candidate * prob_to_update) * effort\n",
    "    if d == -1:\n",
    "        reward = 1 \n",
    "    for route in path.values(): # route\n",
    "        for l in range(len(route) - 1):\n",
    "            pheromone[int(route[l] - 1)][int(route[l+1] - 1)] += reward/cost\n",
    "    reward_coff += d\n",
    "    return reward_coff, pheromone\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AMO-ACO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: Best: 2403.08349609375, Alimentation: 2024.5765600378197\n",
      "epoch 1: Best: 2195.206298828125, Alimentation: 1904.6838884785568\n",
      "epoch 2: Best: 2195.206298828125, Alimentation: 1842.9854056129843\n",
      "epoch 3: Best: 2195.206298828125, Alimentation: 1841.2574730452081\n",
      "epoch 4: Best: 2195.206298828125, Alimentation: 1840.2619391079463\n",
      "epoch 5: Best: 2175.20849609375, Alimentation: 1840.2619391079463\n",
      "epoch 6: Best: 2168.666015625, Alimentation: 1840.2619391079463\n",
      "epoch 7: Best: 2143.786865234375, Alimentation: 1840.2619391079463\n",
      "epoch 8: Best: 2143.786865234375, Alimentation: 1840.2619391079463\n",
      "epoch 9: Best: 2143.786865234375, Alimentation: 1840.2619391079463\n",
      "epoch 10: Best: 2143.786865234375, Alimentation: 1813.7505088914013\n",
      "epoch 11: Best: 2143.786865234375, Alimentation: 1794.3733589348321\n",
      "epoch 12: Best: 2143.786865234375, Alimentation: 1794.373358934832\n",
      "epoch 13: Best: 2143.786865234375, Alimentation: 1794.373358934832\n",
      "epoch 14: Best: 2143.786865234375, Alimentation: 1794.3733589348317\n",
      "epoch 15: Best: 2143.786865234375, Alimentation: 1785.515758839865\n",
      "epoch 16: Best: 2143.786865234375, Alimentation: 1785.5157588398647\n",
      "epoch 17: Best: 2143.786865234375, Alimentation: 1782.8041848754042\n",
      "epoch 18: Best: 2075.716796875, Alimentation: 1782.8041848754042\n",
      "epoch 19: Best: 2075.716796875, Alimentation: 1782.8041848754042\n",
      "epoch 20: Best: 2075.716796875, Alimentation: 1782.8041848754042\n",
      "epoch 21: Best: 2075.716796875, Alimentation: 1782.8041848754042\n",
      "epoch 22: Best: 2075.716796875, Alimentation: 1782.8041848754042\n",
      "epoch 23: Best: 2075.716796875, Alimentation: 1782.8041848754042\n",
      "epoch 24: Best: 2075.716796875, Alimentation: 1782.8041848754042\n",
      "epoch 25: Best: 2075.716796875, Alimentation: 1782.8041848754042\n",
      "epoch 26: Best: 2075.716796875, Alimentation: 1782.8041848754042\n",
      "epoch 27: Best: 2075.716796875, Alimentation: 1782.8041848754042\n",
      "epoch 28: Best: 2018.3985595703125, Alimentation: 1782.8041848754042\n",
      "epoch 29: Best: 2018.3985595703125, Alimentation: 1782.8041848754042\n",
      "epoch 30: Best: 2018.3985595703125, Alimentation: 1782.8041848754042\n",
      "epoch 31: Best: 2018.3985595703125, Alimentation: 1782.8041848754042\n",
      "epoch 32: Best: 2018.3985595703125, Alimentation: 1782.8041848754042\n",
      "epoch 33: Best: 2018.3985595703125, Alimentation: 1782.8041848754042\n",
      "epoch 34: Best: 2018.3985595703125, Alimentation: 1782.8041848754042\n",
      "epoch 35: Best: 2018.3985595703125, Alimentation: 1782.8041848754042\n",
      "epoch 36: Best: 2018.3985595703125, Alimentation: 1782.8041848754042\n",
      "epoch 37: Best: 2018.3985595703125, Alimentation: 1782.8041848754042\n",
      "epoch 38: Best: 2018.3985595703125, Alimentation: 1782.8041848754042\n",
      "epoch 39: Best: 2018.3985595703125, Alimentation: 1782.8041848754042\n",
      "epoch 40: Best: 2018.3985595703125, Alimentation: 1782.8041848754042\n",
      "epoch 41: Best: 2018.3985595703125, Alimentation: 1782.8041848754042\n",
      "<function destroy at 0x292346840>\n",
      "Destroy:  1787.2115307025722\n",
      "epoch 42: Best: 2018.3985595703125, Alimentation: 1782.8041848754042\n",
      "epoch 43: Best: 2018.3985595703125, Alimentation: 1782.303894556785\n",
      "epoch 44: Best: 2018.3985595703125, Alimentation: 1782.2574503841859\n",
      "epoch 45: Best: 2018.3985595703125, Alimentation: 1766.3163015325406\n",
      "epoch 46: Best: 2018.3985595703125, Alimentation: 1762.9020877901723\n",
      "epoch 47: Best: 2018.3985595703125, Alimentation: 1762.9020877901723\n",
      "epoch 48: Best: 2018.3985595703125, Alimentation: 1762.9020877901721\n",
      "epoch 49: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 50: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 51: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 52: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 53: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 54: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 55: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 56: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "<function destroy at 0x292346840>\n",
      "Destroy:  1844.567977816362\n",
      "epoch 57: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 58: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 59: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 60: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 61: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 62: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 63: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 64: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 65: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 66: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 67: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "<function destroy at 0x292346840>\n",
      "Destroy:  1788.6561354806522\n",
      "epoch 68: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 69: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 70: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 71: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 72: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 73: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 74: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 75: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 76: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 77: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 78: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "<function destroy at 0x292346840>\n",
      "Destroy:  1762.902087790173\n",
      "epoch 79: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 80: Best: 2018.3985595703125, Alimentation: 1762.9020877901717\n",
      "epoch 81: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 82: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 83: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 84: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 85: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 86: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 87: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 88: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 89: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 90: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 91: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 92: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "<function destroy at 0x292346840>\n",
      "Destroy:  1762.902087790173\n",
      "epoch 93: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 94: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 95: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 96: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 97: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 98: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n",
      "epoch 99: Best: 1999.6339111328125, Alimentation: 1762.9020877901717\n"
     ]
    }
   ],
   "source": [
    "if options == 0:\n",
    "    import time\n",
    "    lstt = []\n",
    "    max_iteration = cfg.epochs \n",
    "    max_iteration = 300 \n",
    "    n_customer = len(data)\n",
    "    k_candidate = 100\n",
    "    prob_to_update = 0.05\n",
    "    best = 1e10\n",
    "    best_cost = 1e10\n",
    "    aco.decay = 1\n",
    "    aco.beta = 0.5\n",
    "    elitism_set = 0\n",
    "    reward_coff = 1 \n",
    "    effort = 0\n",
    "    final_path = 0\n",
    "    prob_to_destroy = 0.05\n",
    "    cnt = 0\n",
    "    counter = 0\n",
    "    best_data = []\n",
    "    best_cost_data = []\n",
    "    destroy_data = []\n",
    "    t1 = time.time()\n",
    "\n",
    "\n",
    "    def save_solution(ants_route, travel_distance, BTNT, max_route, max_travel):\n",
    "        if len(ants_route.keys()) < max_route:\n",
    "            BTNT[-1] = ants_route\n",
    "            max_travel = travel_distance\n",
    "            max_route = len(ants_route.keys())\n",
    "        elif len(ants_route.keys()) == max_route and travel_distance < max_travel:\n",
    "            BTNT[-1] = ants_route\n",
    "            max_travel = travel_distance\n",
    "            max_route = len(ants_route.keys())\n",
    "        return BTNT, max_travel, max_route\n",
    "\n",
    "\n",
    "    BTNT = [0]\n",
    "    max_travel = 1e10\n",
    "\n",
    "    max_route = int(n_customer)\n",
    "    for k in range(max_iteration):\n",
    "\n",
    "        paths, costs = aco.run()\n",
    "        local_path = []\n",
    "        candidate_values, indexs = torch.topk(costs, k = k_candidate, largest=False)\n",
    "        candidate_path = paths.T[indexs] # (k * prob_size)\n",
    "        for i, (value, path) in enumerate(zip(candidate_values, candidate_path)):\n",
    "            ants_route = convert_dict(path)\n",
    "            if torch.rand(1) < prob_to_update:\n",
    "                travel_distance, ants_route = injection(ants_route, colony, 0.5)\n",
    "                travel_distance, ants_route = cross_exchange(ants_route, colony)\n",
    "                travel_distance, ants_route = ls_1route(ants_route, colony)\n",
    "                travel_distance, ants_route = ls3(ants_route)\n",
    "                BTNT, max_travel, max_route = save_solution(ants_route, travel_distance, BTNT, max_route, max_travel)\n",
    "                candidate_values[i] = travel_distance\n",
    "            local_path.append(ants_route)\n",
    "        \n",
    "        aco.pheromone *= aco.decay\n",
    "        value_to_update, index_to_update = torch.topk(candidate_values, k = int(k_candidate * prob_to_update), largest=False)\n",
    "        for i, j in enumerate(index_to_update):\n",
    "            path = local_path[j] # dict\n",
    "            for route in path.values(): # route\n",
    "                for l in range(len(route) - 1):\n",
    "                    if i == 0:\n",
    "                        aco.pheromone[int(route[l] - 1)][int(route[l+1] - 1)] += 1/value_to_update[i]\n",
    "                    aco.pheromone[int(route[l] - 1)][int(route[l+1] - 1)] += 1/value_to_update[i]\n",
    "        if torch.min(candidate_values) < best:\n",
    "            best = torch.min(candidate_values)\n",
    "            best_path = local_path[index_to_update[0]]\n",
    "            if k > 0 and elitism_set != 0:\n",
    "                path, cost = elitism_set\n",
    "                reward_coff, pheromone = update_btnt(path, cost, aco.pheromone, effort, k_candidate, prob_to_update, reward_coff, best_cost, d = r_coef)\n",
    "                aco.pheromone = pheromone \n",
    "            elitism_set = (best_path, best)  # tuple (path, cost)\n",
    "            effort = 1\n",
    "            tries = 0\n",
    "        \n",
    "        # Alimentation:\n",
    "        if tries == 3 and elitism_set != 0:\n",
    "            tries = 0\n",
    "            path, cost = elitism_set\n",
    "            reward_coff, pheromone = update_btnt(path, cost, aco.pheromone, effort, k_candidate, prob_to_update, reward_coff, best_cost, d=r_coef)\n",
    "            elitism_set = 0\n",
    "            aco.pheromone = pheromone \n",
    "\n",
    "        \n",
    "        if elitism_set == 0:\n",
    "            counter += 1\n",
    "\n",
    "        \n",
    "        if elitism_set != 0:\n",
    "            counter = 0\n",
    "            ants_route, cost = elitism_set\n",
    "            for _ in range(1):\n",
    "                travel_distance, ants_route = injection(ants_route, colony, 0.5)\n",
    "            for _ in range(1):\n",
    "                travel_distance, ants_route = cross_exchange(ants_route, colony)\n",
    "            travel_distance, ants_route = local_search(ants_route, colony, n_customer, cfg.q)\n",
    "            travel_distance, ants_route = ls3(ants_route)\n",
    "            for _ in range(50):\n",
    "                travel_distance, ants_route = ls_1route(ants_route, colony)\n",
    "            BTNT, max_travel, max_route = save_solution(ants_route, travel_distance, BTNT, max_route, max_travel)\n",
    "            if travel_distance < cost:\n",
    "                elitism_set = (ants_route, travel_distance)\n",
    "                effort += 1\n",
    "                if travel_distance < best_cost:\n",
    "                    best_cost = travel_distance \n",
    "                    final_path = ants_route\n",
    "            else:\n",
    "                effort += 1\n",
    "                tries += 1\n",
    "        \n",
    "        if elitism_set == 0 and counter > prob_to_destroy * max_iteration:\n",
    "            print(destroy)\n",
    "            travel_distance, ants_route = destroy(final_path, colony, 0.5)\n",
    "            travel_distance, ants_route = destroy_ls_1route(final_path, colony)\n",
    "            r = np.random.random()\n",
    "            if r < 0.5:\n",
    "                travel_distance, ants_route = ls1(final_path)\n",
    "            else:\n",
    "                travel_distance, ants_route = ls2(final_path)\n",
    "            print(\"Destroy: \", travel_distance)\n",
    "            elitism_set = (ants_route, travel_distance)\n",
    "            counter = 0\n",
    "            destroy_data.append(k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        best_data.append(best)\n",
    "        best_cost_data.append(best_cost)\n",
    "        print('epoch {}: Best: {}, Alimentation: {}'.format(k, best, best_cost))\n",
    "        if (k + 1) % 60 == 0:\n",
    "            lstt.append(best_cost)\n",
    "    t2 = time.time()\n",
    "    time_run = t2-t1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if options == 2:\n",
    "    import time\n",
    "    max_iteration = cfg.epochs \n",
    "    max_iteration = 200 \n",
    "    n_customer = len(data)\n",
    "    k_candidate = 100\n",
    "    prob_to_update = 0.05\n",
    "    best = 1e10\n",
    "    best_cost = 1e10\n",
    "    aco.decay = 1\n",
    "    aco.beta = 0.5\n",
    "    elitism_set = 0\n",
    "    reward_coff = 1\n",
    "    effort = 0\n",
    "    final_path = 0\n",
    "    prob_to_destroy = 0.05\n",
    "    cnt = 0\n",
    "    counter = 0\n",
    "    best_data = []\n",
    "    best_cost_data = []\n",
    "    destroy_data = []\n",
    "    t1 = time.time()\n",
    "\n",
    "\n",
    "    def save_solution(ants_route, travel_distance, BTNT, max_route, max_travel):\n",
    "        if len(ants_route.keys()) < max_route:\n",
    "            BTNT[-1] = ants_route\n",
    "            max_travel = travel_distance\n",
    "            max_route = len(ants_route.keys())\n",
    "        elif len(ants_route.keys()) == max_route and travel_distance < max_travel:\n",
    "            BTNT[-1] = ants_route\n",
    "            max_travel = travel_distance\n",
    "            max_route = len(ants_route.keys())\n",
    "        return BTNT, max_travel, max_route\n",
    "\n",
    "\n",
    "    BTNT = [0]\n",
    "    max_travel = 1e10\n",
    "\n",
    "    max_route = int(n_customer)\n",
    "    for k in range(max_iteration):\n",
    "\n",
    "        paths, costs = aco.run()\n",
    "        local_path = []\n",
    "        candidate_values, indexs = torch.topk(costs, k = k_candidate, largest=False)\n",
    "        candidate_path = paths.T[indexs] # (k * prob_size)\n",
    "        for i, (value, path) in enumerate(zip(candidate_values, candidate_path)):\n",
    "            ants_route = convert_dict(path)\n",
    "            if torch.rand(1) < prob_to_update:\n",
    "                travel_distance, ants_route = injection(ants_route, colony, 0.5)\n",
    "                travel_distance, ants_route = cross_exchange(ants_route, colony)\n",
    "                travel_distance, ants_route = ls_1route(ants_route, colony)\n",
    "                BTNT, max_travel, max_route = save_solution(ants_route, travel_distance, BTNT, max_route, max_travel)\n",
    "                candidate_values[i] = travel_distance\n",
    "            local_path.append(ants_route)\n",
    "\n",
    "        aco.pheromone *= aco.decay\n",
    "        value_to_update, index_to_update = torch.topk(candidate_values, k = int(k_candidate * prob_to_update), largest=False)\n",
    "        for i, j in enumerate(index_to_update):\n",
    "            path = local_path[j] # dict\n",
    "            for route in path.values(): # route\n",
    "                for l in range(len(route) - 1):\n",
    "                    if i == 0:\n",
    "                        aco.pheromone[int(route[l] - 1)][int(route[l+1] - 1)] += 1/value_to_update[i]\n",
    "                    aco.pheromone[int(route[l] - 1)][int(route[l+1] - 1)] += 1/value_to_update[i]\n",
    "        if torch.min(candidate_values) < best:\n",
    "            best = torch.min(candidate_values)\n",
    "            best_path = local_path[index_to_update[0]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        best_data.append(best)\n",
    "        print('epoch {}: Best: {}'.format(k, best))\n",
    "    t2 = time.time()\n",
    "    time_run = t2-t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in range(10):\n",
    "#     ants_route, cost = BTNT[-1], max_travel\n",
    "#     for _ in range(1):\n",
    "#         travel_distance, ants_route = injection(ants_route, colony, 0.5)\n",
    "#     for _ in range(1):\n",
    "#         travel_distance, ants_route = cross_exchange(ants_route, colony)\n",
    "#     travel_distance, ants_route = local_search(ants_route, colony, n_customer, cfg.q)\n",
    "#     travel_distance, ants_route = ls3(ants_route)\n",
    "#     for _ in range(50):\n",
    "#         travel_distance, ants_route = ls_1route(ants_route, colony)\n",
    "#     BTNT, max_travel, max_route = save_solution(ants_route, travel_distance, BTNT, max_route, max_travel)\n",
    "#     print(max_travel, max_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # final_solution = max(1000*max_route + max_travel, 1000*len(final_path.keys()) + best_cost)\n",
    "# # final_solution\n",
    "# if 1000*max_route + max_travel > 1000*len(final_path.keys()) + best_cost:\n",
    "#     final_route = final_path\n",
    "#     final_cost = best_cost\n",
    "#     final_vehicle = len(final_path.keys())\n",
    "# else:\n",
    "#     final_route = BTNT[-1]\n",
    "#     final_cost = max_travel\n",
    "#     final_vehicle = max_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data.txt', 'r') as f:\n",
    "    name = f.readline()\n",
    "name.rstrip()\n",
    "\n",
    "def change_2_save(index, route):\n",
    "    ans = \"Route #{}:\".format(index)\n",
    "    for node in route[1:-1]:\n",
    "        ans += \" \" + str(node-1)\n",
    "    return ans \n",
    "\n",
    "# with open('Solution.txt', 'a') as f:\n",
    "#     f.write(name + '\\n')\n",
    "#     # for id, i in enumerate(final_route.values()):\n",
    "#     #     f.write(change_2_save(id+1, i) + '\\n')\n",
    "#     # f.write(\"Time: {}\".format(round(time_run,2)) + '\\n')\n",
    "#     f.write(\"Vehicle: {}\".format(final_vehicle)+ '\\n')\n",
    "#     f.write(\"Distance: {}\".format(final_cost)+ '\\n')\n",
    "#     f.write(\"-----------------------------------------------\"+ '\\n')\n",
    "\n",
    "best1, best2, best3, best4, best5 = lstt \n",
    "with open('Solution.txt', 'a') as f:\n",
    "    f.write(name + '\\n')\n",
    "    f.write(\"Distance: {} - {} - {} - {} - {}\".format(best1, best2, best3, best4, best5)+ '\\n')\n",
    "    f.write(\"-----------------------------------------------\"+ '\\n')\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
